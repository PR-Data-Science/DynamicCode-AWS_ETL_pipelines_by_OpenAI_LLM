from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, when, regexp_replace, length

# Create Spark session
spark = SparkSession.builder \
    .appName("Data Validation") \
    .getOrCreate()

# Load cleaned dataset
df = spark.read.csv("INvideos.csv", header=True, inferSchema=True)

# Validate publish_time format
timestamp_check = df.filter(~col("publish_time").rlike(r"^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z$"))
if timestamp_check.count() == 0:
    print("✅ Timestamp format is correct")
else:
    print("❌ Timestamps have incorrect formats")

# Validate non-negative numeric columns
numeric_columns = ["views", "likes", "dislikes", "comment_count"]
for column in numeric_columns:
    negative_check = df.filter(col(column) < 0)
    if negative_check.count() == 0:
        print(f"✅ No negative values found in {column}")
    else:
        print(f"❌ Some numeric values are negative in {column}")

# Validate for duplicate rows
if df.count() == df.dropDuplicates().count():
    print("✅ No duplicate rows found")
else:
    print("❌ Duplicate rows exist")

# Validate tags normalization (no special characters)
tags_check = df.filter(col("tags").rlike(r'[^a-zA-Z0-9, ]'))
if tags_check.count() == 0:
    print("✅ Tags are normalized (no special characters)")
else:
    print("❌ Tags contain special characters")

# Validate category_id (assuming valid category_ids are in a predefined list)
valid_category_ids = ['1', '2', '10']  # Example valid IDs
category_check = df.filter(~col("category_id").isin(valid_category_ids))
if category_check.count() == 0:
    print("✅ category_id is valid")
else:
    print("❌ category_id has invalid entries")

# Validate strings for leading/trailing spaces
string_columns = ["title", "channel_title", "description"]
for column in string_columns:
    space_check = df.filter(length(col(column)) != length(regexp_replace(col(column), r'^\s+|\s+$', '')))
    if space_check.count() == 0:
        print(f"✅ No leading/trailing spaces in {column}")
    else:
        print(f"❌ Leading/trailing spaces found in {column}")

# Validate missing tags
missing_tags = df.filter(col("tags").isNull() | (col("tags") == ""))
if missing_tags.count() == 0:
    print("✅ No missing tags")
else:
    print("❌ Missing tags found, they should be replaced with 'No Tags'")

# Validate missing descriptions
missing_description = df.filter(col("description").isNull())
if missing_description.count() == 0:
    print("✅ No missing descriptions")
else:
    print("❌ Missing descriptions found, they should be replaced with ''")

# Stop Spark session
spark.stop()